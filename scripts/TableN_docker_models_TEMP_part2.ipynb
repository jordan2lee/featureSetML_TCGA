{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701fed01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# move into once tableN_docker models notebook runs (this code does a sanity check with my work)\n",
    "\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "extra_options = {\n",
    "    'CF':['All', 'OVERALL'],\n",
    "    'AKLIMATE':[ 'MULTI', 'TOP'], \n",
    "    'skgrid':[ 'OVERALL'],\n",
    "    'subSCOPE':[ 'OVERALL'],\n",
    "    'jadbio':['MULTI']\n",
    "\n",
    "}\n",
    "\n",
    "nameconvert = {\n",
    "    'aklimate':'AKLIMATE', \n",
    "    'cloudforest':'CF',\n",
    "    'jadbio':'jadbio',\n",
    "    'skgrid':'skgrid',\n",
    "    'subscope':'subSCOPE'\n",
    "}\n",
    "\n",
    "\n",
    "with open('../data/table_docker_info/options_extended.yml', 'r') as fh2:\n",
    "    best = yaml.load(fh2, Loader=yaml.Loader)\n",
    "# sanity check my filtering matches christina's\n",
    "# read in christina data \n",
    "perf_df =pd.read_csv('../src/BestModelPerDataTypePerGroup_deduplicated_2022_06_16_fixed_fromChristina.txt', sep='\\t')\n",
    "\n",
    "\n",
    "for algor in extra_options.keys():\n",
    "    for cancer in list(best.keys()):\n",
    "    #     print(cancer)\n",
    "        check= {}\n",
    "        for k,v in best[cancer][algor].items():\n",
    "            if 'info' in k:\n",
    "                # aka don't count the nans\n",
    "                if type(v['Mean_overall_weighted_f1'])!=float:\n",
    "                    # ignore the TOP and OVERALL (will calculate this later)\n",
    "                    if k.split('_')[1] != 'TOP' and k.split('_')[1]!='OVERALL':\n",
    "                        check[k.split('_')[1]]=v['Mean_overall_weighted_f1']\n",
    "\n",
    "        for check_plat in check.keys():\n",
    "            # alimate, jabio reports MULTI as ALL in christinas table\n",
    "            # CF reports All as ALL in christinas table\n",
    "            if check_plat == 'MULTI' or check_plat == 'All': \n",
    "                print('MULTI for ', algor)\n",
    "                s1 = perf_df[(perf_df['cohort']==cancer)&(perf_df['feature_list_method']==algor)][['featureID','cohort','performance_metric','Mean','Std','feature_list_method', 'datatype']]\n",
    "                perf_df_Mean = list(s1[s1['datatype']=='ALL']['Mean'])[0]\n",
    "                assert perf_df_Mean == check[check_plat], 'issue with not matchingup for {} perfdf mean and {} christinas mean. {} {} {}'.format(perf_df_Mean, check[check_plat], cancer, algor, check_plat)        \n",
    "            else:\n",
    "    #             print('checking')\n",
    "                s1 = perf_df[(perf_df['cohort']==cancer)&(perf_df['feature_list_method']==algor)][['featureID','cohort','performance_metric','Mean','Std','feature_list_method', 'datatype']]\n",
    "                perf_df_Mean = list(s1[s1['datatype']==check_plat]['Mean'])[0]\n",
    "                assert perf_df_Mean == check[check_plat], 'issue with not matchingup for {} perfdf mean and {} christinas mean. {} {} {}'.format(perf_df_Mean, check[check_plat],  cancer, algor, check_plat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9634e2e",
   "metadata": {},
   "source": [
    "### sanity check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d84e19",
   "metadata": {},
   "source": [
    "AssertionError: issue with not matchingup for 0.529 perfdf mean and 0.553 christinas mean. ACC AKLIMATE CNVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3093c80e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bmatrix_raw= pd.read_csv('../src/classifier_metrics_20220511/big_results_matrix.tsv', sep='\\t', low_memory=False)\n",
    "\n",
    "#####\n",
    "grp = 'AKLIMATE'\n",
    "c = 'ACC'\n",
    "p = 'CNVR'\n",
    "#####\n",
    "bmatrix = bmatrix_raw[bmatrix_raw['feature_list_method'] == grp]\n",
    "bmatrix = bmatrix[bmatrix['cohort'] == c]\n",
    "bmatrix = bmatrix[bmatrix['performance_metric'] == pmetric].reset_index(drop=True)\n",
    "bmatrix = bmatrix.sort_values(by='Mean', ascending=False)\n",
    "ms = [a for a in bmatrix['model'] if p in a]\n",
    "bmatrix[bmatrix['model'].isin(ms)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba91be10",
   "metadata": {},
   "source": [
    "AssertionError: issue with not matchingup for 0.529 perfdf mean and 0.553 christinas mean. ACC AKLIMATE CNVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a47bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmatrix_raw[bmatrix_raw['total_features']!= '__NO_LIST__'].reset_index(drop=True).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7859220",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmatrix_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcda8bb",
   "metadata": {},
   "source": [
    "### end of sanity check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af1e8d2",
   "metadata": {},
   "source": [
    "### continue with adding in the OVERALL category for that algor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cca0c74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('../data/table_docker_info/options_extended.yml', 'r') as fh2:\n",
    "    best = yaml.load(fh2, Loader=yaml.Loader)\n",
    "\n",
    "# determine which algors need to calculate overall\n",
    "models_need_overall= []\n",
    "for k,v in extra_options.items():\n",
    "    if 'OVERALL' not in v:\n",
    "        models_need_overall.append(k)\n",
    "# add in OVERALL = highest performance of all models from that algor\n",
    "# thus will say which model of AKLIAMTE is OVERALL, then for skgrid, etc\n",
    "for algor in models_need_overall:\n",
    "    for cancer in list(best.keys()):\n",
    "        # find the model \n",
    "        overall_4_algor = {'model':'NA', 'score': 0}\n",
    "        for KEY in [a for a in best[cancer][algor].keys() if 'info' in a]:\n",
    "            perform = best[cancer][algor][KEY]['Mean_overall_weighted_f1']\n",
    "            if perform > overall_4_algor['score']:\n",
    "                overall_4_algor['score']=perform\n",
    "                overall_4_algor['model']=KEY\n",
    "        best[cancer][algor]['OVERALL']= best[cancer][algor][KEY.split('_')[1]]\n",
    "        best[cancer][algor]['info_OVERALL']= best[cancer][algor][overall_4_algor['model']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ba90c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bcc510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull up info used in docker models\n",
    "with open('../../../09_docker/gdan-tmp-models/tools/model_info.json', 'r') as file:\n",
    "    info = yaml.safe_load(file)\n",
    "\n",
    "reverse_name = {\n",
    "    'AKLIMATE':'aklimate', \n",
    "    'CF':'cloudforest',\n",
    "    'jadbio':'jadbio',\n",
    "    'skgrid':'skgrid',\n",
    "    'subSCOPE':'subscope'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410ab32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best[cancer][algor][platform] # NO_MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adff0e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24370ae2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a41b70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all info into 1 df\n",
    "# #####\n",
    "algor = 'CF'\n",
    "cancer = 'BRCA'\n",
    "# #####\n",
    "# skgrid\n",
    "\n",
    "res = {'Command':[], 'Mean_Overall_Weighted_F1':[],'Std_overall_weighted_f1':[], 'Cohort': [], 'Platform': [], 'Algorithm_Method':[],'Features':[]}\n",
    "for cancer in best.keys():\n",
    "    for algor in best[cancer].keys():\n",
    "        \n",
    "        platform_cyles = [a for a in best[cancer][algor] if 'info' in a]\n",
    "        # update the above\n",
    "        \n",
    "        for pc in platform_cyles:\n",
    "            platform = pc.split('_')[1]\n",
    "            # skip when don't have model info on that \n",
    "            if 'NO_MODEL' not in best[cancer][algor][platform]:\n",
    "                res['Command'].append('bash RUN_model.sh {} {} {} YOUR-DATA.tsv'.format(cancer, platform, reverse_name[algor]))\n",
    "\n",
    "                mean_value = best[cancer][algor][pc]['Mean_overall_weighted_f1']\n",
    "                res['Mean_Overall_Weighted_F1'].append(mean_value)\n",
    "\n",
    "                sd_value = best[cancer][algor][pc]['Std_overall_weighted_f1']\n",
    "                res['Std_overall_weighted_f1'].append(sd_value)\n",
    "\n",
    "                res['Cohort'].append(cancer)\n",
    "\n",
    "                # modify in table TOP to OVERALL but command col will use TOP still\n",
    "                if platform == 'TOP':\n",
    "                    res['Platform'].append('OVERALL')\n",
    "                elif platform == 'All':\n",
    "                    res['Platform'].append('MULTI')\n",
    "                else:\n",
    "                    res['Platform'].append(platform)\n",
    "\n",
    "                res['Algorithm_Method'].append(reverse_name[algor])\n",
    "\n",
    "                fts = info[reverse_name[algor]][cancer][platform]['fts']\n",
    "                res['Features'].append(fts)\n",
    "            else:\n",
    "                res['Command'].append('NA')\n",
    "\n",
    "                res['Mean_Overall_Weighted_F1'].append('NA')\n",
    "\n",
    "                res['Std_overall_weighted_f1'].append('NA')\n",
    "\n",
    "                res['Cohort'].append(cancer)\n",
    "\n",
    "                # modify in table TOP to OVERALL but command col will use TOP still\n",
    "                if platform == 'TOP':\n",
    "                    res['Platform'].append('OVERALL')\n",
    "                elif platform == 'All':\n",
    "                    res['Platform'].append('MULTI')\n",
    "                else:\n",
    "                    res['Platform'].append(platform)\n",
    "\n",
    "                res['Algorithm_Method'].append(reverse_name[algor])\n",
    "\n",
    "                res['Features'].append('NA')                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fcc5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "info[reverse_name[algor]][cancer].keys()\n",
    "algor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1c9d44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c91ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "info[reverse_name[algor]][cancer].keys()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8454ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary = pd.DataFrame.from_dict(res)\n",
    "summary = summary.sort_values(by = ['Mean_Overall_Weighted_F1','Cohort', 'Platform','Algorithm_Method'], ascending =[False, False,False, False]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1656ccd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42b9fa3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8704ce33",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.sort_values(by = 'Cohort', ascending =True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7afc7c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
