{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197bd232",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# note this is PART of the code from get_model_info_ALL.ipynb\n",
    "\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import numpy as np\n",
    "\n",
    "### 1. Get performance info\n",
    "# Get top performing models\n",
    "df = pd.read_csv('../../../08_manuscript/featureSetML_TCGA/src/classifier_metrics_20220511/big_results_matrix.tsv', sep='\\t', low_memory=False)\n",
    "\n",
    "platform_options = {\n",
    "    'CF':['GEXP' , 'CNVR', 'METH', 'MUTA', 'MIR', 'All', 'OVERALL'],\n",
    "    'AKLIMATE':['GEXP' , 'CNVR', 'METH', 'MUTA', 'MIR', 'MULTI', 'TOP'], \n",
    "    'skgrid':['GEXP' , 'CNVR', 'METH', 'MUTA', 'MIR', 'OVERALL'],\n",
    "    'subSCOPE':['GEXP' , 'CNVR', 'METH', 'MUTA', 'MIR', 'OVERALL'],\n",
    "    'jadbio':['GEXP' , 'CNVR', 'METH', 'MUTA', 'MIR', 'MULTI']\n",
    "\n",
    "}\n",
    "\n",
    "groups = ['AKLIMATE', 'CF', 'jadbio', 'skgrid', 'subSCOPE']\n",
    "cancers = ['BRCA', 'LGGGBM', 'COADREAD', 'SKCM', 'ACC', 'BLCA', 'CESC', 'ESCC', 'GEA', 'HNSC', 'KIRCKICH', 'KIRP', 'LIHCCHOL', 'LUAD', 'LUSC', 'MESO', 'OV', 'PAAD', 'PCPG', 'PRAD', 'SARC', 'TGCT', 'THCA', 'THYM', 'UCEC', 'UVM']\n",
    "pmetric = 'overall_weighted_f1'\n",
    "filters = 100 # max size of ft list\n",
    "    \n",
    "best = {}\n",
    "for cancer in cancers: \n",
    "    print(cancer)\n",
    "    # For a group: select best model\n",
    "    ct = 1\n",
    "    cancer_dict = {}\n",
    "    for group in groups:\n",
    "        # remove rows where no feature list len provided\n",
    "        # note this might be a spot need to fix later\n",
    "        df = df[df['total_features']!= '__NO_LIST__'].reset_index(drop=True)\n",
    "        # change type of col\n",
    "        df['total_features'] = df['total_features'].astype('int')\n",
    "\n",
    "        # Grabs all models for: method, cancer, overall_weighted_f1\n",
    "        subset = df[df['feature_list_method'] == group]\n",
    "        subset = subset[subset['cohort'] == cancer]\n",
    "        subset = subset[subset['performance_metric'] == pmetric].reset_index(drop=True)\n",
    "        # filter for max ft size\n",
    "        max_ft_size = int(filters)\n",
    "        subset = subset[subset['total_features'] <= max_ft_size].reset_index(drop=True)\n",
    "        subset = subset.sort_values(by='Mean', ascending=False)\n",
    "\n",
    "        # Get the model for each platform\n",
    "        platforms = platform_options[group]\n",
    "        for platform in platforms:\n",
    "            col_options = ['GEXP_features','CNVR_features','MIR_features','MUTA_features','METH_features']\n",
    "\n",
    "            # filter models specific to group\n",
    "            if group == 'CF':\n",
    "                if platform != 'OVERALL':\n",
    "                    # CF specific. featureid has info of platform at index 3\n",
    "                    # note: \"All\" is at index2 (CF_ACC_All_Top_100). must use all datatypes\n",
    "                    ftid_keep= [f for f in subset['featureID'] if f.split('_')[2]==platform]\n",
    "                    platform_subset = subset[subset['featureID'].isin(ftid_keep)].reset_index(drop=True)\n",
    "                # no filtering done.  \"OVERALL\" is the best single or multi data type model.\n",
    "                else:\n",
    "                    platform_subset = subset\n",
    "            elif group == 'AKLIMATE':\n",
    "                print(platform)\n",
    "                # AKLIMATE specific. featureid has info of platform at index 1\n",
    "                # single platform is AKLIMATE_METH_ONLY_BRCA_reduced_model_5_feature_set_BRCA\n",
    "                if platform in ['GEXP' , 'CNVR', 'METH', 'MUTA', 'MIR']:    \n",
    "                    ftid_keep= [f for f in subset['featureID'] if f.split('_')[1]==platform]\n",
    "                    platform_subset = subset[subset['featureID'].isin(ftid_keep)].reset_index(drop=True)\n",
    "                # # \"MULTI\" can use all platform is AKLIMATE_BRCA_reduced_model_100_feature_set_BRCA\n",
    "                elif platform =='MULTI':\n",
    "                    ftid_keep= [f for f in subset['featureID'] if f.split('_')[2]!='ONLY']\n",
    "                    platform_subset = subset[subset['featureID'].isin(ftid_keep)].reset_index(drop=True)\n",
    "                # no filtering done.  \"TOP\" is the best single or multi data type model.\n",
    "                elif platform == 'TOP':\n",
    "                    platform_subset = subset \n",
    "            elif group =='skgrid':\n",
    "                if platform in ['GEXP' , 'CNVR', 'METH', 'MUTA', 'MIR']:\n",
    "                    ftid_keep= [f for f in subset['featureID'] if f.split('_')[3]=='perplatform'+platform]\n",
    "                    platform_subset = subset[subset['featureID'].isin(ftid_keep)].reset_index(drop=True)\n",
    "                elif platform =='OVERALL':\n",
    "                    # no filtering done.  \"OVERALL\" is the best single or multi data type model.\n",
    "                    platform_subset = subset  \n",
    "            elif group == 'subSCOPE':\n",
    "                # note we do not have a statement for \"ENSEMBLE\" which can use multiple datatypes\n",
    "                if platform in ['GEXP' , 'CNVR', 'METH', 'MUTA', 'MIR']:\n",
    "                    if platform == 'CNVR':\n",
    "                        ftid_keep = [f for f in subset['featureID'] if f.split('_')[0]=='subSCOPE-'+platform.replace('R', '')]\n",
    "                    else:\n",
    "                        ftid_keep= [f for f in subset['featureID'] if f.split('_')[0]=='subSCOPE-'+platform]\n",
    "                    platform_subset= subset[subset['featureID'].isin(ftid_keep)].reset_index(drop=True)\n",
    "                elif platform =='OVERALL':\n",
    "                    # no filtering done. where OVERALL is the best single or multi data type model\n",
    "                    platform_subset = subset  \n",
    "            elif group == 'jadbio':\n",
    "                if platform in ['GEXP' , 'CNVR', 'METH', 'MUTA', 'MIR']:    \n",
    "                    ftid_keep= [f for f in subset['featureID'] if f.split('_')[2]==platform]\n",
    "                    platform_subset = subset[subset['featureID'].isin(ftid_keep)].reset_index(drop=True)\n",
    "                elif platform =='MULTI':\n",
    "                    ftid_keep= [f for f in subset['featureID'] if f.split('_')[2]=='MULTIDATATYPE']\n",
    "                    platform_subset = subset[subset['featureID'].isin(ftid_keep)].reset_index(drop=True)\n",
    "                elif group== 'OVERALL':\n",
    "                    # no filtering done. where OVERALL is the best single or multi data type model\n",
    "                    platform_subset = subset  \n",
    "\n",
    "\n",
    "            # Grab name of model wit ht eh highest MEWAN performance metic (overall balanced f1)\n",
    "            platform_subset = platform_subset.sort_values(by='Mean', ascending=False).reset_index(drop=True)\n",
    "            # if found at least one model\n",
    "            if platform_subset.shape[0] > 0:\n",
    "                ftID = platform_subset.sort_values(by='Mean', ascending=False).reset_index(drop=True)['featureID'][0]\n",
    "            #else no models fitting the above filters, need to finish\n",
    "            else:\n",
    "                ftID = 'NO_MODEL_MATCH_' + group\n",
    "            # note can grab 'model' col at this point too if want, it will be located at row 0\n",
    "\n",
    "            # save\n",
    "            if group not in cancer_dict:\n",
    "                cancer_dict[group] ={platform:ftID}\n",
    "                # add new extra info\n",
    "                if ftID.startswith('NO_MODEL_MATCH_'):\n",
    "                    cancer_dict[group]['info_'+platform]= {'Mean_'+pmetric: np.nan, \n",
    "                     'Std_'+pmetric: np.nan, \n",
    "                     'Max_'+pmetric:np.nan,\n",
    "                     'full_featureID': np.nan,\n",
    "                     'full_model':np.nan,\n",
    "                    }   \n",
    "                else:\n",
    "                    cancer_dict[group]['info_'+platform]= {'Mean_'+pmetric: platform_subset['Mean'][0], \n",
    "                     'Std_'+pmetric: platform_subset['Std'][0],\n",
    "                     'Max_'+pmetric: platform_subset['Max'][0],\n",
    "                     'full_featureID': platform_subset['featureID'][0],\n",
    "                     'full_model':platform_subset['model'][0],\n",
    "                    }                \n",
    "            else:\n",
    "                cancer_dict[group][platform] =ftID\n",
    "                # add new extra info\n",
    "                if ftID.startswith('NO_MODEL_MATCH_'):\n",
    "                    cancer_dict[group]['info_'+platform]= {'Mean_'+pmetric:np.nan, \n",
    "                     'Std_'+pmetric: np.nan, \n",
    "                     'Max_'+pmetric:np.nan,\n",
    "                     'full_featureID': np.nan,\n",
    "                     'full_model':np.nan,\n",
    "                    }   \n",
    "                else:\n",
    "                    cancer_dict[group]['info_'+platform]= {'Mean_'+pmetric: platform_subset['Mean'][0], \n",
    "                     'Std_'+pmetric: platform_subset['Std'][0], \n",
    "                     'Max_'+pmetric: platform_subset['Max'][0],\n",
    "                     'full_featureID': platform_subset['featureID'][0],\n",
    "                     'full_model':platform_subset['model'][0],\n",
    "                    }      \n",
    "            print(ftID, ' selected as best model for group')\n",
    "            \n",
    "    best[cancer]=cancer_dict\n",
    "\n",
    "\n",
    "\n",
    "# save this ref file \n",
    "with open('../tools/options_extended.yml', 'w') as fh:\n",
    "    yaml.dump(best, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94cfe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "best['BRCA']['skgrid']['info_OVERALL']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99568c9",
   "metadata": {},
   "source": [
    "# Pause to update '../tools/model_info.json' so contains 'OVERALL' etc\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7279d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what has been added \n",
    "# OVERALL - cloudforest\n",
    "\n",
    "\n",
    "# pull up info used in docker models\n",
    "with open('../tools/model_info.json', 'r') as file:\n",
    "    info = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e98b6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best['BRCA']['skgrid']['info_OVERALL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093f8801",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "platform_options = {\n",
    "    'CF':['GEXP' , 'CNVR', 'METH', 'MUTA', 'MIR', 'All', 'OVERALL'],\n",
    "    'AKLIMATE':['GEXP' , 'CNVR', 'METH', 'MUTA', 'MIR', 'MULTI', 'TOP'], \n",
    "    'skgrid':['GEXP' , 'CNVR', 'METH', 'MUTA', 'MIR', 'OVERALL'],\n",
    "    'subSCOPE':['GEXP' , 'CNVR', 'METH', 'MUTA', 'MIR', 'OVERALL'],\n",
    "    'jadbio':['GEXP' , 'CNVR', 'METH', 'MUTA', 'MIR', 'MULTI']\n",
    "\n",
    "}\n",
    "nameconvert = {\n",
    "    'aklimate':'AKLIMATE', \n",
    "    'cloudforest':'CF',\n",
    "    'jadbio':'jadbio',\n",
    "    'skgrid':'skgrid',\n",
    "    'subscope':'subSCOPE'\n",
    "}\n",
    "\n",
    "\n",
    "#####\n",
    "cancer = 'BRCA'\n",
    "####\n",
    "# Add in info for \"OVERALL\"\n",
    "for algor in ['skgrid', 'cloudforest', 'aklimate', 'subscope', 'jadbio']:\n",
    "    if 'OVERALL' in platform_options[nameconvert[algor]]:\n",
    "        print(algor)\n",
    "\n",
    "#         # Sanity check: get all platforms for that cancer-algor combo in \"best\"\n",
    "#         platforms = [a for a in list(best[cancer][nameconvert[algor]].keys()) if 'info' not in a]\n",
    "#         for plat in platforms:\n",
    "#             # if not in info_dict then we want to add it\n",
    "#             if plat not in info[algor][cancer]:\n",
    "#                 print(plat, 'not in info_dict for', algor, cancer)\n",
    "\n",
    "\n",
    "        # determing which platform has the best score for that cancer-algor combo\n",
    "        opts = [a for a in best[cancer][nameconvert[algor]].keys() if 'info' in a]\n",
    "        print(opts)\n",
    "        high_score = 0\n",
    "        high_platform = 'NA'\n",
    "        for op in opts:\n",
    "            score = best[cancer][nameconvert[algor]][op]['Mean_overall_weighted_f1']\n",
    "            print(high_score, op)\n",
    "            if score >high_score:\n",
    "                high_score = score\n",
    "                high_platform = op.split('_')[1]\n",
    "                print('updated to', high_platform, high_score)\n",
    "        # add that meta data info of high_platfrom as the 'OVERALL' or 'TOP'\n",
    "        assert high_platform!='NA'\n",
    "        print('OVERALL winner was', high_platform)\n",
    "        info[algor][cancer]['OVERALL']=info[algor][cancer][high_platform]\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ed9d2e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO need to check why jadbio-brca-overall isn't showing gexp as the winner,\n",
    "# shown in the updated dict is MULTI...\n",
    "best['BRCA']['jadbio']['info_METH']['Max_overall_weighted_f1']\n",
    "\n",
    "# best[cancer][nameconvert[algor]][op]['Mean_overall_weighted_f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5934516",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c604d707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359c79a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pandas as pd \n",
    "\n",
    "### 2. Build summary table\n",
    "with open('../tools/options_extended.yml', 'r') as fh2:\n",
    "    best = yaml.load(fh2, Loader=yaml.Loader)\n",
    "    \n",
    "# pull up info used in docker models\n",
    "with open('../tools/model_info.json', 'r') as file:\n",
    "    info = yaml.safe_load(file)\n",
    "    \n",
    "nameconvert = {\n",
    "    'aklimate':'AKLIMATE', \n",
    "    'cloudforest':'CF',\n",
    "    'jadbio':'jadbio',\n",
    "    'skgrid':'skgrid',\n",
    "    'subscope':'subSCOPE'\n",
    "}\n",
    "\n",
    "res = {'Cohort': [], 'Platform': [], 'Algorithm_Method':[], 'Max_Overall_Weighted_F1':[], 'Mean_Overall_Weighted_F1':[],'Features':[]}\n",
    "\n",
    "for algor in info.keys():\n",
    "    for cancer in info[algor].keys():\n",
    "        for platform in info[algor][cancer].keys():\n",
    "\n",
    "            res['Cohort'].append(cancer)\n",
    "            res['Platform'].append(platform)\n",
    "            res['Algorithm_Method'].append(algor)\n",
    "            fts_list = info[algor][cancer][platform]['fts']\n",
    "#             fts_list = ', '.join([a.split(':')[3] + '('+ a.split(':')[4]+')' for a in fts_list])\n",
    "            fts_list = ','.join(fts_list)\n",
    "            res['Features'].append(fts_list)\n",
    "        \n",
    "            perf = float(best[cancer][nameconvert[algor]]['info_'+platform]['Max_overall_weighted_f1'])\n",
    "            res['Max_Overall_Weighted_F1'].append(perf)\n",
    "            \n",
    "            perf = float(best[cancer][nameconvert[algor]]['info_'+platform]['Mean_overall_weighted_f1'])\n",
    "            res['Mean_Overall_Weighted_F1'].append(perf)      \n",
    "summary = pd.DataFrame.from_dict(res)\n",
    "summary = summary.sort_values(by = ['Cohort','Platform','Max_Overall_Weighted_F1', 'Algorithm_Method'], ascending =[True,False, False, False]).reset_index(drop=True)\n",
    "# remove the max overall weighted f1 column\n",
    "summary = summary.drop('Max_Overall_Weighted_F1', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80c126d",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.to_csv('../tools/table_models.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c00ad5",
   "metadata": {},
   "source": [
    "# Option 2\n",
    "dependent on running the last section of option 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385fde5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Table 1: Rows = data type, columns = cohort, values = single top algorithm (ex. SK Grid, AKLIMATE, etc) with mean overall_weighted_f1\n",
    "res_2 = {'OVERALL':[],'TOP':[],'CNVR':[], 'GEXP':[], 'METH':[], 'MIR':[], 'MULTI':[], 'MUTA':[], 'All':[]}\n",
    "index_list = []\n",
    "cancers_list = sorted(list(set(summary['Cohort'])))\n",
    "\n",
    "\n",
    "for cancer in cancers_list:\n",
    "    for platform in res_2.keys():\n",
    "        # Get the best model for cohort-platform (pick best model of the 5 algors)\n",
    "        s1 = summary[(summary['Platform']==platform)&(summary['Cohort']==cancer)].sort_values(by='Mean_Overall_Weighted_F1', ascending =False).reset_index(drop=True)\n",
    "        try:\n",
    "            model = s1['Algorithm_Method'][0]\n",
    "            perf= s1['Mean_Overall_Weighted_F1'][0]\n",
    "            fts = s1['Features'][0]\n",
    "        # if no hits\n",
    "        except:\n",
    "            model = 'NA'\n",
    "            perf='NA'\n",
    "            fts='NA'\n",
    "\n",
    "        # build out table (transposed)\n",
    "        res_2[platform].append(str(model + ' ('+str(perf)+')'))\n",
    "    index_list.append(cancer)\n",
    "    \n",
    "summary_2 = pd.DataFrame.from_dict(res_2)\n",
    "summary_2.index = index_list\n",
    "summary_2.to_csv('../tools/table_models.option2a.tsv', sep='\\t', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30472253",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Table 2: Rows = data type, columns = cohort, values = feature list\n",
    "res_2 = {'OVERALL':[],'TOP':[],'CNVR':[], 'GEXP':[], 'METH':[], 'MIR':[], 'MULTI':[], 'MUTA':[], 'All':[]}\n",
    "index_list = []\n",
    "cancers_list = sorted(list(set(summary['Cohort'])))\n",
    "\n",
    "\n",
    "for cancer in cancers_list:\n",
    "    for platform in res_2.keys():\n",
    "        # Get the best model for cohort-platform (pick best model of the 5 algors)\n",
    "        s1 = summary[(summary['Platform']==platform)&(summary['Cohort']==cancer)].sort_values(by='Mean_Overall_Weighted_F1', ascending =False).reset_index(drop=True)\n",
    "        try:\n",
    "            model = s1['Algorithm_Method'][0]\n",
    "            perf= s1['Features'][0]\n",
    "            fts = s1['Features'][0]\n",
    "        # if no hits\n",
    "        except:\n",
    "            model = 'NA'\n",
    "            perf='NA'\n",
    "            fts='NA'\n",
    "\n",
    "        # build out table (transposed)\n",
    "        res_2[platform].append(perf)\n",
    "    index_list.append(cancer)\n",
    "    \n",
    "summary_2 = pd.DataFrame.from_dict(res_2)\n",
    "summary_2.index = index_list\n",
    "summary_2.to_csv('../tools/table_models.option2b.tsv', sep='\\t', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be809bf0",
   "metadata": {},
   "source": [
    "# Option 3\n",
    "dependent on running the last 2 sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4e5bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 1: Rows = data type, columns = cohort, values = single top algorithm (ex. SK Grid, AKLIMATE, etc) with mean overall_weighted_f1\n",
    "res_2 = {'OVERALL':[],'TOP':[],'CNVR':[], 'GEXP':[], 'METH':[], 'MIR':[], 'MULTI':[], 'MUTA':[], 'All':[]}\n",
    "index_list = []\n",
    "cancers_list = sorted(list(set(summary['Cohort'])))\n",
    "\n",
    "\n",
    "for cancer in cancers_list:\n",
    "    for platform in res_2.keys():\n",
    "        # Get the best model for cohort-platform (pick best model of the 5 algors)\n",
    "        s1 = summary[(summary['Platform']==platform)&(summary['Cohort']==cancer)].sort_values(by='Mean_Overall_Weighted_F1', ascending =False).reset_index(drop=True)\n",
    "        try:\n",
    "            model = s1['Algorithm_Method'][0]\n",
    "            perf= s1['Mean_Overall_Weighted_F1'][0]\n",
    "            fts = s1['Features'][0]\n",
    "        # if no hits\n",
    "        except:\n",
    "            model = 'NA'\n",
    "            perf='NA'\n",
    "            fts='NA'\n",
    "\n",
    "        # build out table (transposed)\n",
    "        res_2[platform].append(str(model + ' ('+str(perf)+') ')+ fts)\n",
    "    index_list.append(cancer)\n",
    "    \n",
    "summary_2 = pd.DataFrame.from_dict(res_2)\n",
    "summary_2.index = index_list\n",
    "summary_2.to_csv('../tools/table_models.option3.tsv', sep='\\t', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb2c251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4327ebb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e02f2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4870c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "214a27a6",
   "metadata": {},
   "source": [
    "# debug\n",
    "\n",
    "options as per github readme\n",
    "\n",
    "skgrid: OVERALL, (CNVR, GEXP, METH, MIR, MUTA)\n",
    "\n",
    "aklimate: TOP, MULTI, (GEXP, CNVR, METH) ( MIR AND MUTA???)\n",
    "\n",
    "cloudforest: OVERALL, All, (CNVR, GEXP, METH, MIR, MUTA)\n",
    "\n",
    "subscope: allcohorts, (CNVR, GEXP, METH, MIR, MUTA)\n",
    "\n",
    "jabio: MULTI, (CNVR, GEXP, METH, MIR, MUTA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d37d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t2 = df[df['cohort']=='BRCA']\n",
    "# t2 = t2[t2['performance_metric']=='overall_weighted_f1'].sort_values(by='Mean', ascending =False)\n",
    "# t2\n",
    "\n",
    "t2 = summary[summary['Cohort']=='BRCA']\n",
    "t2 = t2[t2['Platform']=='OVERALL'].sort_values(by='Mean_Overall_Weighted_F1', ascending =False)\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49cd5bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257d5fff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loli = pd.read_csv('/Users/leejor/Downloads/LollipopPlotInput.txt', sep='\\t')\n",
    "loli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89b5a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(loli['feature_list_method'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355f1734",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4e177d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9def8097",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary[(summary['Cohort']=='BRCA')&(summary['Algorithm_Method']=='skgrid')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2561aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary[(summary['Platform']=='OVERALL')&(summary['Algorithm_Method']=='skgrid')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5d335c",
   "metadata": {},
   "source": [
    "# data from chirstina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe942227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what has been added \n",
    "# OVERALL - cloudforest\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "nameconvert = {\n",
    "    'aklimate':'AKLIMATE', \n",
    "    'cloudforest':'CF',\n",
    "    'jadbio':'jadbio',\n",
    "    'skgrid':'skgrid',\n",
    "    'subscope':'subSCOPE'\n",
    "}\n",
    "\n",
    "# pull up info used in docker models\n",
    "with open('../tools/model_info.json', 'r') as file:\n",
    "    info = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6340bd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in christina data \n",
    "perf_df =pd.read_csv('../../../08_manuscript/featureSetML_TCGA/src/BestModelPerDataTypePerGroup_deduplicated_2022_06_16_fixed_fromChristina.txt', sep='\\t')\n",
    "perf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78be0c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('TODO update to get performance info for All and MULTI and OVERALL and TOP (note in df it shows All not ALL)')\n",
    "for algor in info.keys():\n",
    "    for cancer in info[algor].keys():\n",
    "        for platform in info[algor][cancer].keys():\n",
    "            # pull performance info from christina's reduced file\n",
    "            s1 = perf_df[(perf_df['feature_list_method']==nameconvert[algor])&(perf_df['cohort']==cancer)&(perf_df['datatype']==platform)]\n",
    "            \n",
    "            if s1.shape[0]!=0:\n",
    "                assert s1.shape[0]==1, 'shape is {}'.format(s1.shape)\n",
    "                performance = list(s1['Mean'])[0]\n",
    "\n",
    "                # add that performance to info dictionary\n",
    "                info[algor][cancer][platform]['Mean_Overall_Weighted_F1']=performance\n",
    "            # if algor wasn't ran for that combo of cancer-platform\n",
    "            else:\n",
    "                info[algor][cancer][platform]['Mean_Overall_Weighted_F1'] ='NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbf14b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "res = {'Cohort': [], 'Platform': [], 'Algorithm_Method':[], 'Mean_Overall_Weighted_F1':[],'Features':[]}\n",
    "\n",
    "for algor in info.keys():\n",
    "    for cancer in info[algor].keys():\n",
    "        for platform in info[algor][cancer].keys():\n",
    "\n",
    "            res['Cohort'].append(cancer)\n",
    "            res['Platform'].append(platform)\n",
    "            res['Algorithm_Method'].append(algor)\n",
    "            fts_list = info[algor][cancer][platform]['fts']\n",
    "#             fts_list = ', '.join([a.split(':')[3] + '('+ a.split(':')[4]+')' for a in fts_list])\n",
    "            fts_list = ','.join(fts_list)\n",
    "            res['Features'].append(fts_list)\n",
    "        \n",
    "#             perf = float(best[cancer][nameconvert[algor]]['info_'+platform]['Max_overall_weighted_f1'])\n",
    "#             res['Max_Overall_Weighted_F1'].append(perf)\n",
    "            \n",
    "            perf = info[algor][cancer][platform]['Mean_Overall_Weighted_F1']\n",
    "            res['Mean_Overall_Weighted_F1'].append(perf)      \n",
    "summary = pd.DataFrame.from_dict(res)\n",
    "summary = summary.sort_values(by = ['Cohort','Mean_Overall_Weighted_F1', 'Platform','Algorithm_Method'], ascending =[True,False, False, False]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bef021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp fix to drop {'All', 'MULTI', 'OVERALL', 'TOP'} bc not ready with this info yet\n",
    "print('TODO update so this removal step of all multi overall top is not occuring')\n",
    "# set(summary[summary['Mean_Overall_Weighted_F1']=='NA']['Platform'])\n",
    "summary= summary[summary['Mean_Overall_Weighted_F1']!='NA']\n",
    "summary = summary.sort_values(by = ['Cohort','Mean_Overall_Weighted_F1', 'Platform','Algorithm_Method'], ascending =[True,False, False, False]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7933dac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.to_csv('../tools/table_models.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc28694",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
