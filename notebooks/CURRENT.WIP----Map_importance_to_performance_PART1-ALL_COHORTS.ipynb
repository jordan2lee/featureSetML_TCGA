{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init conversion dictionary\n",
    "# RUN ONLY ONCE\n",
    "perform2imp = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### hardcoded strings\n",
    "####\n",
    "\n",
    "f_imp = '../src/classifier_metrics_20210821/feature_importance.tsv'\n",
    "df_imp_raw = pd.read_csv(f_imp, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_options= ['aklimate', 'CF', 'jadbio', 'subSCOPE', 'skgrid']\n",
    "team_imp_options = ['aklimate', 'cloudforest', 'jadbio', 'subscope', 'skgrid']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skgrid_get_more_model_info(cancer):\n",
    "    '''skgrid in normal pipeline doesnt have enough info to pinpoint one ft selection\n",
    "    method and classification so need to pull classification info\n",
    "    \n",
    "    Reason: skgrid needs info on classifier to match best model\n",
    "    '''\n",
    "    # Open file\n",
    "    f_pred = '../src/classifier_metrics_20210821/top_performing_models_lte_100_features.tsv'\n",
    "    df_pred = pd.read_csv(f_pred, sep='\\t')\n",
    "    \n",
    "    # Get classifcation info\n",
    "    skgrid_s1 = df_pred[df_pred['feature_list_method']=='skgrid']\n",
    "    skgrid_s1 = skgrid_s1[skgrid_s1['cohort']==cancer].reset_index(drop=True)\n",
    "    if skgrid_s1.shape[0]==1:\n",
    "        selected_skgrid_model = skgrid_s1['model'][0]\n",
    "        return(\n",
    "            '## SKGRID ONLY. featureID and model info\\n{}\\n{}'.format(skgrid_s1['featureID'][0], selected_skgrid_model), \n",
    "            selected_skgrid_model\n",
    "        )\n",
    "    else:\n",
    "        return(\n",
    "            'MULTIPLE TIED PERFORMING MODELS (N={})'.format(skgrid_s1.shape[0]),\n",
    "            list(skgrid_s1['model'])\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# first attempt is to cycle through all cancers for one team, then move to next team\n",
    "# for dev this is easiest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "cancer_list = ['ACC', 'BLCA', 'BRCA', 'CESC', 'COADREAD', 'ESCC', 'GEA', 'HNSC', 'KIRCKICH', 'KIRP', 'LGGGBM', 'LIHCCHOL', 'LUAD', 'LUSC', 'MESO', 'OV', 'PAAD', 'PCPG', 'PRAD', 'SARC', 'SKCM', 'TGCT', 'THCA', 'THYM', 'UCEC', 'UVM']\n",
    "\n",
    "######\n",
    "for cancer in cancer_list:\n",
    "    print(cancer)\n",
    "    ######\n",
    "    i = 3 # for team selection\n",
    "    ######\n",
    "    # Select Team\n",
    "    selected_team = team_options[i]\n",
    "    selected_team_imp = team_imp_options[i]\n",
    "    print('{} and {} selected from list'.format(selected_team, selected_team_imp))\n",
    "\n",
    "\n",
    "    # Set up out file\n",
    "    f_out = '../src/conversions/' + selected_team + '.json'\n",
    "\n",
    "    # Run only if skgrid for more info to pinpoint model. Outputs variable and logging info\n",
    "    if selected_team == 'skgrid':\n",
    "        info , selected_skgrid_model = skgrid_get_more_model_info(cancer)\n",
    "        print(info)\n",
    "\n",
    "\n",
    "    # Find top model for a team\n",
    "    f_top = '../data/figure_panel_a/best_models_{}.tsv'.format(cancer)\n",
    "    df_top = pd.read_csv(f_top, sep='\\t', index_col=0)\n",
    "    top_models = list(df_top.columns)\n",
    "    print('Best models options:\\n')\n",
    "    for t in top_models:\n",
    "        print(t)\n",
    "\n",
    "    # Create source dictionary of conversions - this need to be tested on all cancers to see if works\n",
    "    # TODO\n",
    "\n",
    "    # k:v == team_options to model prefix in top_models\n",
    "    mini_conversion_prefix = {\n",
    "        'aklimate' : 'AKLIMATE', \n",
    "        'CF' : 'CF', #no change\n",
    "        'jadbio' : 'jadbio', #no change\n",
    "        'subSCOPE' : 'subSCOPE', \n",
    "        'skgrid' :'skgrid' #nochange\n",
    "    }\n",
    "\n",
    "\n",
    "    # Select Team to work on\n",
    "    team_prefix = mini_conversion_prefix[selected_team]\n",
    "    for m in top_models:\n",
    "        if m.startswith(team_prefix):\n",
    "            selected_model = m\n",
    "            print(selected_model, '\\nwas assigned to\\n', selected_team)\n",
    "            exit\n",
    "\n",
    "\n",
    "    # Subset for team and cancer\n",
    "    df_imp = df_imp_raw[df_imp_raw['method']==selected_team_imp]\n",
    "    keep = []\n",
    "    for v in df_imp['feature_importance_ID']:\n",
    "        if cancer in v:\n",
    "            keep.append(v)\n",
    "    df_imp= df_imp[df_imp['feature_importance_ID'].isin(keep)].reset_index(drop=True)\n",
    "    print('{} models found'.format(df_imp.shape[0]))\n",
    "\n",
    "\n",
    "    # Find row that matches with selected_model description\n",
    "\n",
    "    # src dictionary specfic to team key words in feature_importance_ID column\n",
    "    substring_dict = {\n",
    "        'aklimate' : { # no MIR importances reported\n",
    "            'CNVR_ONLY' : 'CNVR_ONLY', #nochange\n",
    "            'GEXP_ONLY' : 'GEXP_ONLY', #nochange\n",
    "            'METH_ONLY' : 'METH_ONLY', #nochange\n",
    "            'MULTI_DATA' : 'MULTI_DATA', #nochange\n",
    "        },\n",
    "        'CF' :{\n",
    "            'All' : 'All', #nochange\n",
    "            'CNVR' : 'CNVR', #nochange\n",
    "            'GEXP' : 'GEXP', #nochange\n",
    "            'METH' : 'METH', #nochange\n",
    "            'MIR' : 'MIR', #nochange\n",
    "            'MUTA' : 'MUTA', #nochange\n",
    "        },\n",
    "        'jadbio' : {\n",
    "            'CNVR' : 'CNVR', #nochange\n",
    "            'GEXP' : 'GEXP', #nochange\n",
    "            'METH' : 'METH', #nochange\n",
    "            'MIR' : 'MIR', #nochange\n",
    "            'MUTA' : 'MUTA', #nochange\n",
    "            'MULTIDATATYPE' : 'MULTIDATATYPE', #nochange\n",
    "        },\n",
    "        'subSCOPE' : {\n",
    "            'CNVR' : 'CNVR', #nochange\n",
    "            'GEXP' : 'GEXP', #nochange\n",
    "            'METH' : 'METH', #nochange\n",
    "            'MIR' : 'MIR', #nochange\n",
    "            'MUTA' : 'MUTA', #nochange\n",
    "            'ENSEMBLE' : 'ENSEMBLE', #nochange\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # src dictionary if no matches from substring_dict. these are the assumed values\n",
    "    gap_substring_dict = {\n",
    "        'aklimate' : 'MULTI_DATA'\n",
    "    }\n",
    "\n",
    "\n",
    "    # 1. Find substring present in selected model\n",
    "    found = 'false'\n",
    "    for potential_substring in substring_dict[selected_team].keys():\n",
    "        if potential_substring in selected_model:\n",
    "            lookup_key = potential_substring\n",
    "            found = 'true'\n",
    "            exit\n",
    "    if found == 'false': # if no hits from above\n",
    "        lookup_key = gap_substring_dict[selected_team]\n",
    "        print('uses this')\n",
    "    # 2. Use that to find substring to use in df_imp\n",
    "    df_lookup_key = substring_dict[selected_team][lookup_key]\n",
    "    print(df_lookup_key)\n",
    "\n",
    "    # 3. Find matching model and add to perform2imp \n",
    "    for i in range(0, df_imp.shape[0]):\n",
    "        if df_lookup_key in df_imp['feature_importance_ID'][i]:\n",
    "            df_model = df_imp.iloc[i,:]['feature_importance_ID']\n",
    "            print('at row {} found match of\\n{}\\n\\tto\\n{}'.format(i, selected_model, df_model))\n",
    "            perform2imp[selected_model]= df_imp.iloc[i,:]['feature_importance_ID']\n",
    "            exit\n",
    "\n",
    "    # Output conversion keys - will overwrite old file with new one each loop\n",
    "    with open(f_out, 'w') as out:\n",
    "        out.write(json.dumps(perform2imp))\n",
    "        out.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STOP - next section is one at a time, only keeping for deve for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC\n"
     ]
    }
   ],
   "source": [
    "######\n",
    "cancer_list = ['ACC', 'BLCA', 'BRCA', 'CESC', 'COADREAD', 'ESCC', 'GEA', 'HNSC', 'KIRCKICH', 'KIRP', 'LGGGBM', 'LIHCCHOL', 'LUAD', 'LUSC', 'MESO', 'OV', 'PAAD', 'PCPG', 'PRAD', 'SARC', 'SKCM', 'TGCT', 'THCA', 'THYM', 'UCEC', 'UVM']\n",
    "cancer = cancer_list[0]\n",
    "print(cancer)\n",
    "######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skgrid and skgrid selected from list\n"
     ]
    }
   ],
   "source": [
    "######\n",
    "i = 4\n",
    "######\n",
    "# Select Team\n",
    "selected_team = team_options[i]\n",
    "selected_team_imp = team_imp_options[i]\n",
    "print('{} and {} selected from list'.format(selected_team, selected_team_imp))\n",
    "\n",
    "\n",
    "# Set up out file\n",
    "f_out = '../src/conversions/' + selected_team + '.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# need to add this to above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## SKGRID ONLY. featureID and model info\n",
      "skgrid_ACC_fbedeBIC_perplatformALL_ACC\n",
      "skgrid_ExtraTrees(criterion=gini,n_estimators=128)|skgrid_ACC.tsv_skgrid_ACC_fbedeBIC_perplatformALL|ACC.tsv_skgrid_ACC_fbedeBIC_perplatformALL|2021-01-13|c\n"
     ]
    }
   ],
   "source": [
    "# Run only if skgrid for more info to pinpoint model. Outputs variable and logging info\n",
    "if selected_team == 'skgrid':\n",
    "    info , selected_skgrid_model = skgrid_get_more_model_info(cancer)\n",
    "    print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best models options:\n",
      "\n",
      "AKLIMATE_ACC_reduced_model_100_feature_set_ACC\n",
      "CF_ACC_MIR_Top_100_ACC\n",
      "jadbio_ACC_GEXP_cumulative_feature_set18_ACC\n",
      "skgrid_ACC_fbedeBIC_perplatformALL_ACC\n",
      "subSCOPE-GEXP_2021-04-21_bootstrapfeatures_ACC_ACC\n"
     ]
    }
   ],
   "source": [
    "# Find top model for a team\n",
    "f_top = '../data/figure_panel_a/best_models_{}.tsv'.format(cancer)\n",
    "df_top = pd.read_csv(f_top, sep='\\t', index_col=0)\n",
    "top_models = list(df_top.columns)\n",
    "print('Best models options:\\n')\n",
    "for t in top_models:\n",
    "    print(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create source dictionary of conversions - this need to be tested on all cancers to see if works\n",
    "# TODO\n",
    "\n",
    "# k:v == team_options to model prefix in top_models\n",
    "mini_conversion_prefix = {\n",
    "    'aklimate' : 'AKLIMATE', \n",
    "    'CF' : 'CF', #no change\n",
    "    'jadbio' : 'jadbio', #no change\n",
    "    'subSCOPE' : 'subSCOPE', \n",
    "    'skgrid' :'skgrid' #nochange\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skgrid_ACC_fbedeBIC_perplatformALL_ACC \n",
      "was assigned to\n",
      " skgrid\n"
     ]
    }
   ],
   "source": [
    "# Select Team to work on\n",
    "team_prefix = mini_conversion_prefix[selected_team]\n",
    "for m in top_models:\n",
    "    if m.startswith(team_prefix):\n",
    "        selected_model = m\n",
    "        print(selected_model, '\\nwas assigned to\\n', selected_team)\n",
    "        exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Look up feature importance scores ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6214 models found\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>feature_importance_ID</th>\n",
       "      <th>json_object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>skgrid</td>\n",
       "      <td>KNeighborsClassifier(algorithm=auto,leaf_size=...</td>\n",
       "      <td>{\"feature_importance_ID\": \"KNeighborsClassifie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>skgrid</td>\n",
       "      <td>KNeighborsClassifier(algorithm=auto,leaf_size=...</td>\n",
       "      <td>{\"feature_importance_ID\": \"KNeighborsClassifie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>skgrid</td>\n",
       "      <td>KNeighborsClassifier(algorithm=auto,leaf_size=...</td>\n",
       "      <td>{\"feature_importance_ID\": \"KNeighborsClassifie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>skgrid</td>\n",
       "      <td>KNeighborsClassifier(algorithm=auto,leaf_size=...</td>\n",
       "      <td>{\"feature_importance_ID\": \"KNeighborsClassifie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>skgrid</td>\n",
       "      <td>KNeighborsClassifier(algorithm=auto,leaf_size=...</td>\n",
       "      <td>{\"feature_importance_ID\": \"KNeighborsClassifie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6209</th>\n",
       "      <td>skgrid</td>\n",
       "      <td>SGDClassifier(alpha=0.01,loss=log,penalty=elas...</td>\n",
       "      <td>{\"feature_importance_ID\": \"SGDClassifier(alpha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6210</th>\n",
       "      <td>skgrid</td>\n",
       "      <td>SGDClassifier(alpha=0.01,loss=modified_huber,p...</td>\n",
       "      <td>{\"feature_importance_ID\": \"SGDClassifier(alpha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6211</th>\n",
       "      <td>skgrid</td>\n",
       "      <td>SGDClassifier(alpha=0.01,loss=modified_huber,p...</td>\n",
       "      <td>{\"feature_importance_ID\": \"SGDClassifier(alpha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6212</th>\n",
       "      <td>skgrid</td>\n",
       "      <td>SGDClassifier(alpha=0.01,loss=modified_huber,p...</td>\n",
       "      <td>{\"feature_importance_ID\": \"SGDClassifier(alpha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6213</th>\n",
       "      <td>skgrid</td>\n",
       "      <td>SGDClassifier(alpha=0.01,loss=squared_hinge,pe...</td>\n",
       "      <td>{\"feature_importance_ID\": \"SGDClassifier(alpha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6214 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      method                              feature_importance_ID  \\\n",
       "0     skgrid  KNeighborsClassifier(algorithm=auto,leaf_size=...   \n",
       "1     skgrid  KNeighborsClassifier(algorithm=auto,leaf_size=...   \n",
       "2     skgrid  KNeighborsClassifier(algorithm=auto,leaf_size=...   \n",
       "3     skgrid  KNeighborsClassifier(algorithm=auto,leaf_size=...   \n",
       "4     skgrid  KNeighborsClassifier(algorithm=auto,leaf_size=...   \n",
       "...      ...                                                ...   \n",
       "6209  skgrid  SGDClassifier(alpha=0.01,loss=log,penalty=elas...   \n",
       "6210  skgrid  SGDClassifier(alpha=0.01,loss=modified_huber,p...   \n",
       "6211  skgrid  SGDClassifier(alpha=0.01,loss=modified_huber,p...   \n",
       "6212  skgrid  SGDClassifier(alpha=0.01,loss=modified_huber,p...   \n",
       "6213  skgrid  SGDClassifier(alpha=0.01,loss=squared_hinge,pe...   \n",
       "\n",
       "                                            json_object  \n",
       "0     {\"feature_importance_ID\": \"KNeighborsClassifie...  \n",
       "1     {\"feature_importance_ID\": \"KNeighborsClassifie...  \n",
       "2     {\"feature_importance_ID\": \"KNeighborsClassifie...  \n",
       "3     {\"feature_importance_ID\": \"KNeighborsClassifie...  \n",
       "4     {\"feature_importance_ID\": \"KNeighborsClassifie...  \n",
       "...                                                 ...  \n",
       "6209  {\"feature_importance_ID\": \"SGDClassifier(alpha...  \n",
       "6210  {\"feature_importance_ID\": \"SGDClassifier(alpha...  \n",
       "6211  {\"feature_importance_ID\": \"SGDClassifier(alpha...  \n",
       "6212  {\"feature_importance_ID\": \"SGDClassifier(alpha...  \n",
       "6213  {\"feature_importance_ID\": \"SGDClassifier(alpha...  \n",
       "\n",
       "[6214 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subset for team and cancer\n",
    "df_imp = df_imp_raw[df_imp_raw['method']==selected_team_imp]\n",
    "keep = []\n",
    "for v in df_imp['feature_importance_ID']:\n",
    "    if cancer in v:\n",
    "        keep.append(v)\n",
    "df_imp= df_imp[df_imp['feature_importance_ID'].isin(keep)].reset_index(drop=True)\n",
    "print('{} models found'.format(df_imp.shape[0]))\n",
    "df_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will need to manually pick the row index that matches the selected model description\n",
    "# ex. if only gexp then select the only gexp model\n",
    "# skip down "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only for skgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR - MUST RUN CODE IN SEVERAL CELLS BELOW FOR SKGRID ONLY\n"
     ]
    }
   ],
   "source": [
    "if selected_team == 'skgrid':\n",
    "    print('ERROR - MUST RUN CODE IN SEVERAL CELLS BELOW FOR SKGRID ONLY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'skgrid_ExtraTrees(criterion=gini,n_estimators=128)|skgrid_ACC.tsv_skgrid_ACC_fbedeBIC_perplatformALL|ACC.tsv_skgrid_ACC_fbedeBIC_perplatformALL|2021-01-13|c'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dev to check out, delete this cell later\n",
    "selected_skgrid_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updatedupdated\n",
    "skgrid_function_dict = {\n",
    "    'ExtraTrees' : 'ExtraTreesClassifier'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ExtraTrees(criterion=gini,n_estimators=128)|skgrid_ACC.tsv_skgrid_ACC_fbedeBIC_perplatformALL|ACC.tsv_skgrid_ACC_fbedeBIC_perplatformALL|2021-01-13|c'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# updatedupdated\n",
    "\n",
    "# input skgrid selected_model object\n",
    "input_model = 'skgrid_ExtraTrees(criterion=gini,n_estimators=128)|skgrid_ACC.tsv_skgrid_ACC_fbedeBIC_perplatformALL|ACC.tsv_skgrid_ACC_fbedeBIC_perplatformALL|2021-01-13|c'\n",
    "\n",
    "# Remove skgrid prefix\n",
    "modified_model = '_'.join(input_model.strip().split('_')[1:])\n",
    "modified_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ExtraTreesClassifier(criterion=gini,n_estimators=128)|skgrid_ACC.tsv_skgrid_ACC_fbedeBIC_perplatformALL|ACC.tsv_skgrid_ACC_fbedeBIC_perplatformALL|2021-01-13|c'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update ML function name if needed\n",
    "func_name = modified_model.split('(')[0]\n",
    "new_func_name = skgrid_function_dict[func_name]\n",
    "modified_model = new_func_name +'('+'('.join(modified_model.split('(')[1:])\n",
    "modified_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ExtraTreesClassifier(criterion=gini,n_estimators=128)',\n",
       " 'ACC.tsv_skgrid_ACC_fbedeBIC_perplatformALL',\n",
       " '2021-01-13',\n",
       " 'c']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean up ft selection and other misc info in model string\n",
    "modified_model = modified_model.strip().split('|')\n",
    "del modified_model[1] # remove second item\n",
    "\n",
    "new_ft_method = modified_model[1].split('.tsv_')[1] # remove cancer.tsv_ prefix\n",
    "\n",
    "final_model = '|'.join([modified_model[0], new_ft_method, modified_model[2], modified_model[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now look up model in df\n",
    "df_imp =df_imp[df_imp['feature_importance_ID']==final_model].reset_index(drop=True)\n",
    "\n",
    "assert df_imp.shape[0] == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Find matching model and add to perform2imp \n",
    "perform2imp[selected_model]=df_imp['feature_importance_ID'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for sk grid only\n",
    "# # filter 1\n",
    "# keep =[]\n",
    "# for v in df_imp['feature_importance_ID']:\n",
    "#     if 'criterion=entropy,n_estimators=200' in v:\n",
    "#         keep.append(v)\n",
    "# s3 = df_imp[df_imp['feature_importance_ID'].isin(keep)].reset_index(drop=True)\n",
    "\n",
    "# # filter 2\n",
    "# keep =[]\n",
    "# for v in s3['feature_importance_ID']:\n",
    "#     if 'BRCA_fbedeBIC_perplatformALL' in v:\n",
    "#         keep.append(v)\n",
    "        \n",
    "# s3 = df_imp[df_imp['feature_importance_ID'].isin(keep)].reset_index(drop=True)      \n",
    "# for a in s3['feature_importance_ID']:\n",
    "#     print(a)\n",
    "    \n",
    "\n",
    "# # df_imp[df_imp['feature_importance_ID']=='RandomForestClassifier(criterion=entropy,n_estimators=200)|skgrid_BRCA_fbedeBIC_perplatformALL|2021-01-13|c']\n",
    "\n",
    "# # pulled index from above line\n",
    "# line3921 = json.loads(df_imp.iloc[3921,:]['json_object'])['feature_importance_scores']\n",
    "# line10135 = json.loads(df_imp.iloc[10135,:]['json_object'])['feature_importance_scores']\n",
    "# print('are these dups the same? {}'.format(line10135==line3921))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in info.strip().split('\\n'):\n",
    "    print(i)\n",
    "    print()\n",
    "    if i.startswith('MULTIPLE TIED PERFORMING MODELS'):\n",
    "        for m in selected_skgrid_model:\n",
    "            print(m)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sk grid only\n",
    "# filter 1\n",
    "keep =[]\n",
    "for v in df_imp['feature_importance_ID']:\n",
    "    if 'LogisticRegression' in v: # HERE #\n",
    "        keep.append(v)\n",
    "s3 = df_imp[df_imp['feature_importance_ID'].isin(keep)].reset_index(drop=True)\n",
    "\n",
    "# filter 2\n",
    "keep = []\n",
    "for v in s3['feature_importance_ID']:\n",
    "    if 'C=10,max_iter=500,solver=liblinear' in v: # HERE #\n",
    "        keep.append(v)\n",
    "s3 = s3[s3['feature_importance_ID'].isin(keep)].reset_index(drop=True)\n",
    "\n",
    "# filter 3\n",
    "keep =[]\n",
    "for v in s3['feature_importance_ID']:\n",
    "    if 'fbedeBIC_perplatformALL' in v: # HERE #\n",
    "        keep.append(v)\n",
    "        \n",
    "s3 = df_imp[df_imp['feature_importance_ID'].isin(keep)].reset_index(drop=True) \n",
    "for a in s3['feature_importance_ID']:\n",
    "    print(a)\n",
    "    \n",
    "df_imp[df_imp['feature_importance_ID']==a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # debug\n",
    "# for s in s3['feature_importance_ID']:\n",
    "#     print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK if there are dups that the dups are the same\n",
    "# pulled index from above line\n",
    "lineA = json.loads(df_imp.iloc[498,:]['json_object'])['feature_importance_scores']\n",
    "lineB = json.loads(df_imp.iloc[6712,:]['json_object'])['feature_importance_scores']\n",
    "print('are these dups the same? {}'.format(lineA==lineB))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to every team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find row that matches with selected_model description\n",
    "\n",
    "# updatedupdated\n",
    "\n",
    "# src dictionary specfic to team key words in feature_importance_ID column\n",
    "substring_dict = {\n",
    "    'aklimate' : { # no MIR importances reported\n",
    "        'CNVR_ONLY' : 'CNVR_ONLY', #nochange\n",
    "        'GEXP_ONLY' : 'GEXP_ONLY', #nochange\n",
    "        'METH_ONLY' : 'METH_ONLY', #nochange\n",
    "        'MULTI_DATA' : 'MULTI_DATA', #nochange\n",
    "    },\n",
    "    'CF' :{\n",
    "        'All' : 'All', #nochange\n",
    "        'CNVR' : 'CNVR', #nochange\n",
    "        'GEXP' : 'GEXP', #nochange\n",
    "        'METH' : 'METH', #nochange\n",
    "        'MIR' : 'MIR', #nochange\n",
    "        'MUTA' : 'MUTA', #nochange\n",
    "    },\n",
    "    'jadbio' : {\n",
    "        'CNVR' : 'CNVR', #nochange\n",
    "        'GEXP' : 'GEXP', #nochange\n",
    "        'METH' : 'METH', #nochange\n",
    "        'MIR' : 'MIR', #nochange\n",
    "        'MUTA' : 'MUTA', #nochange\n",
    "        'MULTIDATATYPE' : 'MULTIDATATYPE', #nochange\n",
    "    }\n",
    "}\n",
    "\n",
    "# src dictionary if no matches from substring_dict. these are the assumed values\n",
    "gap_substring_dict = {\n",
    "    'aklimate' : 'MULTI_DATA'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Find substring present in selected model\n",
    "found = 'false'\n",
    "for potential_substring in substring_dict[selected_team].keys():\n",
    "    if potential_substring in selected_model:\n",
    "        lookup_key = potential_substring\n",
    "        found = 'true'\n",
    "        exit\n",
    "if found == 'false': # if no hits from above\n",
    "    lookup_key = gap_substring_dict[selected_team]\n",
    "    print('uses this')\n",
    "# 2. Use that to find substring to use in df_imp\n",
    "df_lookup_key = substring_dict[selected_team][lookup_key]\n",
    "print(df_lookup_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Find matching model and add to perform2imp \n",
    "for i in range(0, df_imp.shape[0]):\n",
    "    if df_lookup_key in df_imp['feature_importance_ID'][i]:\n",
    "        df_model = df_imp.iloc[i,:]['feature_importance_ID']\n",
    "        print('at row {} found match of\\n{}\\n\\tto\\n{}'.format(i, selected_model, df_model))\n",
    "        perform2imp[selected_model]= df_imp.iloc[i,:]['feature_importance_ID']\n",
    "        exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for k,v in perform2imp.items():\n",
    "    print('{} \\n\\t{}'.format(k,v))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output conversion keys\n",
    "with open(f_out, 'w') as out:\n",
    "    out.write(json.dumps(perform2imp))\n",
    "    out.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
